{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e96702-5d06-4b2b-b650-a4e2825a4b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "# Add a path to the module search path\n",
    "sys.path.append('../')\n",
    "from nodeood.data import TEGenerator, ADSGenerator\n",
    "from nodeood.data import RandomSampler\n",
    "from nodeood.datasets import OGBNArxiv, Planetoid\n",
    "from nodeood.methods import Naive\n",
    "from nodeood.backbones import GCN\n",
    "from nodeood.utils import set_random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a74fd2f-af58-4ed4-9fa6-4da4fce89b94",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fundamentals: DRData and DRDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa0a4a-afd8-4bb3-92cf-e59e3252e333",
   "metadata": {},
   "source": [
    "DRData describes a homogeneous graph in DeepRobust2.0. <br>\n",
    "DRData inherits from torch_geometric.data.Data, so we can use various useful functionalities for analyzing graph structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cffb50-060d-4988-b44d-103ec57cface",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nodeood.data import DRData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c57ead0-8bfe-40e6-be9d-7dd54df5d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a graph\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "data = DRData(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598af009-1041-43b5-a2d8-b7f4c9605437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Nodes: 3\n",
      "Is directed: False\n"
     ]
    }
   ],
   "source": [
    "# Analyzing the graph structure:\n",
    "print(f'# Nodes: {data.num_nodes}')\n",
    "print(f'Is directed: {data.is_directed()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d132b-7b6b-443c-8bf3-a5307ea234a9",
   "metadata": {},
   "source": [
    "DRDataset is an abstract class representing a graph dataset. A DRDataset contains one or more than one DRData. <br>\n",
    "DRDataset is responsible for downloading, (customized) processing, and persistence of graphs. <br>\n",
    "In the following sections, we will provide several examples to load and process datasets under different settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8256a3-41aa-481e-935c-7e96917a613a",
   "metadata": {},
   "source": [
    "## Setting 1: Load Cora with public split (single graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "874e2bdb-f4f5-4423-b26a-3a452cd31e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c54e19-1945-4607-93dd-1f688490a05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Planetoid/cora/public/dataset.zip\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(data_dir, name='cora', mode='public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec681268-22bc-42f1-a114-11d1b60455cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planetoid()\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59eded7-d714-4350-93b8-9d91672f0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc4e385b-1c85-4021-8acf-ff94ca94d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRData(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1557eaaa-651a-4c92-8be4-59a1eb64dcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train nodes: 140\n",
      "# val nodes: 500\n",
      "# test nodes: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'# train nodes: {data.train_mask.sum()}')\n",
    "print(f'# val nodes: {data.val_mask.sum()}')\n",
    "print(f'# test nodes: {data.test_mask.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d005ce3-4563-4208-b1a1-da40520be7ea",
   "metadata": {},
   "source": [
    "## Setting 2: Generate node splits for Cora (single graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1a031-2c18-4ca5-a721-b2e554f88add",
   "metadata": {},
   "source": [
    "A sampler is used to generate masks for the input graph to simulate a certain distribution shift between training and testing NODES. <br>\n",
    "We now define a simple generator to generate train, val and test nodes randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab3fee7e-1f37-4692-a8bb-86ca4b0145fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://ghproxy.com/https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://ghproxy.com/https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://ghproxy.com/https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://ghproxy.com/https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://ghproxy.com/https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://ghproxy.com/https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://ghproxy.com/https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from nodeood.data import RandomSampler\n",
    "sampler = RandomSampler(n_node_per_class=20, n_val=500, n_test=1000, seed=123)\n",
    "dataset = Planetoid(data_dir, name='cora', mode='sampler', sampler=sampler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6ae857c-c40a-4b40-addb-8a2582b5360f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train nodes: 140\n",
      "# val nodes: 500\n",
      "# test nodes: 1000\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(f'# train nodes: {data.train_mask.sum()}')\n",
    "print(f'# val nodes: {data.val_mask.sum()}')\n",
    "print(f'# test nodes: {data.test_mask.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea2114-8aa9-467d-836e-60acd8b8f474",
   "metadata": {},
   "source": [
    "## Setting 3: Load Cora with Artificial Distribution Shift (ADS) from EERM (multiple graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75e422e6-1271-4989-9528-655eae79d1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Planetoid/cora/eerm-gcn/dataset.zip\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_train = Planetoid(data_dir, name='cora', mode='eerm-gcn', split='train')\n",
    "dataset_val = Planetoid(data_dir, name='cora', mode='eerm-gcn', split='val')\n",
    "dataset_test = Planetoid(data_dir, name='cora', mode='eerm-gcn', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004596b1-ce92-4116-98dc-d926535fde27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: # graphs: 1\n",
      "Valid set: # graphs: 1\n",
      "Test set: # graphs: 8\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set: # graphs: {len(dataset_train)}')\n",
    "print(f'Valid set: # graphs: {len(dataset_val)}')\n",
    "print(f'Test set: # graphs: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd77c3ae-8e26-47a5-ab63-7948ac344a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also load other variants of Cora from EERM (e.g., EERM-GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "935ad422-cea0-4b82-b87b-a28def0f309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Planetoid/cora/eerm-gat/dataset.zip\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_train = Planetoid(data_dir, name='cora', mode='eerm-gat', split='train')\n",
    "dataset_val = Planetoid(data_dir, name='cora', mode='eerm-gat', split='val')\n",
    "dataset_test = Planetoid(data_dir, name='cora', mode='eerm-gat', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f32810-b26b-4711-b6c0-c7306d0cc08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: # graphs: 1\n",
      "Valid set: # graphs: 1\n",
      "Test set: # graphs: 8\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set: # graphs: {len(dataset_train)}')\n",
    "print(f'Valid set: # graphs: {len(dataset_val)}')\n",
    "print(f'Test set: # graphs: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7186f1c7-e759-423b-a00e-c68e5f2827b8",
   "metadata": {},
   "source": [
    "## Setting 4: Generate new variants for Cora using ADS generator (multiple graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68441f-a64d-480b-a251-3bc43b486417",
   "metadata": {},
   "source": [
    "A generator is used to generate MULTIPLE graphs from ONE given graph to simulate a certain distribution shift between GRAPHS. <br>\n",
    "We now define an ADSGenerator to create Artificial Distribution Shift from paper 'EERM'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456f77a3-affe-4c70-8df0-de99cad3d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "# processed graphs: [10<10]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from nodeood.data import ADSGenerator\n",
    "# We need to define a Dict to specify the desired splits of the generated graphs\n",
    "split = {'train': [0], 'val': [1], 'test': list(range(2, 10))}\n",
    "generator = ADSGenerator(n_graph=10, n_class=10, n_feat=10, n_hid=10, model='gcn', seed=12345, split=split)\n",
    "# Now we can get datasets containing the graphs generated by ADSGenerator\n",
    "dataset_train = Planetoid(data_dir, name='cora', mode='generator', split='train', generator=generator)\n",
    "dataset_val = Planetoid(data_dir, name='cora', mode='generator', split='val', generator=generator)\n",
    "dataset_test = Planetoid(data_dir, name='cora', mode='generator', split='test', generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22221800-5ad5-43f6-aff3-42ee193df0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: # graphs: 1\n",
      "Valid set: # graphs: 1\n",
      "Test set: # graphs: 8\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set: # graphs: {len(dataset_train)}')\n",
    "print(f'Valid set: # graphs: {len(dataset_val)}')\n",
    "print(f'Test set: # graphs: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e0230-826e-4925-b2ce-8109339bbb7d",
   "metadata": {},
   "source": [
    "Note that the generated graphs are saved to disk with the name of a hash string representing the generator used when the first time generating them. <br> \n",
    "After that, processing will be skipped for the same generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc1041-3922-4483-b28a-67eddf13d689",
   "metadata": {},
   "source": [
    "## Setting 5: Split temporal graphs by time: take OGBN-Arxiv for example "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f687039-73cc-494e-804b-a3ecf398e3b9",
   "metadata": {},
   "source": [
    "We can use a TEGenerator to split a temporal graph to create Temporal Evolution shift. <br>\n",
    "In this case, the input graph will be split by the time nodes were added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f11c7f5-632b-4961-8706-7104dbb12678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/OGBNArxiv/edge.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 6/6 [00:01<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/OGBNArxiv/node_year.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 2/2 [00:00<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/OGBNArxiv/node-feat.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.07 GB: 100%|██████████| 74/74 [00:05<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/OGBNArxiv/node-label.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 2/2 [00:00<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/OGBNArxiv/num-edge-list.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 2/2 [00:00<00:00, 415.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/OGBNArxiv/num-node-list.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 2/2 [00:00<00:00, 451.75it/s]\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# processed graphs: [5<5]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from nodeood.datasets import OGBNArxiv\n",
    "from nodeood.data import TEGenerator\n",
    "# We need to define a Dict to specify the time spans to split the input graph\n",
    "split = {'train': [[1950, 2011]], 'val': [[2011, 2014]], 'test': [[2014, 2016], [2016, 2018], [2018, 2020]]}\n",
    "generator = TEGenerator(split=split)\n",
    "dataset_train = OGBNArxiv(data_dir, mode='generator', split='train', generator=generator)\n",
    "dataset_val = OGBNArxiv(data_dir, mode='generator', split='val', generator=generator)\n",
    "dataset_test = OGBNArxiv(data_dir, mode='generator', split='test', generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e323cd5-ae35-44d0-ae64-089efa9aea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: # graphs: 1\n",
      "Valid set: # graphs: 1\n",
      "Test set: # graphs: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set: # graphs: {len(dataset_train)}')\n",
    "print(f'Valid set: # graphs: {len(dataset_val)}')\n",
    "print(f'Test set: # graphs: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cf6d461-3f4d-4752-9666-17e0766f6320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train:0, # Nodes: 17401, Test Time Span: [1971, 2011].\n",
      "Dataset: val:0, # Nodes: 41125, Test Time Span: [2012, 2014].\n",
      "Dataset: test:0, # Nodes: 69499, Test Time Span: [2015, 2016].\n",
      "Dataset: test:1, # Nodes: 120740, Test Time Span: [2017, 2018].\n",
      "Dataset: test:2, # Nodes: 169343, Test Time Span: [2019, 2020].\n"
     ]
    }
   ],
   "source": [
    "for name, dataset in zip(['train', 'val', 'test'], [dataset_train, dataset_val, dataset_test]):\n",
    "    for i in range(len(dataset)):\n",
    "        data = dataset[i]\n",
    "        span = [data.node_year[data.mask].min().item(), data.node_year[data.mask].max().item()]\n",
    "        print(f'Dataset: {name}:{i}, # Nodes: {data.num_nodes}, Test Time Span: {span}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26116798-0eb2-41cc-8002-0795f5d68fc5",
   "metadata": {},
   "source": [
    "## Setting 6: Load Twitch - A set of graphs from multiple domains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "343e3181-939b-415d-9bb5-ac4897f42b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nodeood.datasets import Twitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d108fa6-349e-4688-8df8-004e0aa54281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DE', 'ENGB', 'ES', 'FR', 'PTBR', 'RU', 'TW']\n"
     ]
    }
   ],
   "source": [
    "names = Twitch.get_names()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d03daa9-1d6c-4cda-a844-6adf8900385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Twitch/ENGB/musae_ENGB_edges.csv\n",
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Twitch/ENGB/musae_ENGB_features.json\n",
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Twitch/ENGB/musae_ENGB_target.csv\n",
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Twitch/FR/musae_FR_edges.csv\n",
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Twitch/FR/musae_FR_features.json\n",
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Twitch/FR/musae_FR_target.csv\n",
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Twitch/TW/musae_TW_edges.csv\n",
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Twitch/TW/musae_TW_features.json\n",
      "Downloading https://ghproxy.com/https://raw.githubusercontent.com/SongYYYY/DeepRobustData/master/Twitch/TW/musae_TW_target.csv\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitch(3)\n",
      "Dataset Details:\n",
      "Number of graphs:  3\n",
      "Graph name: ENGB\n",
      "Graph name: FR\n",
      "Graph name: TW\n"
     ]
    }
   ],
   "source": [
    "# We can load one or more graphs from the above domains\n",
    "domains = ['ENGB', 'FR', 'TW']\n",
    "dataset = Twitch(data_dir, domains)\n",
    "print(dataset)\n",
    "print('Dataset Details:')\n",
    "print('Number of graphs: ', len(dataset))\n",
    "for i in range(len(dataset)):\n",
    "    data = dataset[i]\n",
    "    print('Graph name: {}'.format(data.name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
